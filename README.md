# Chapter 9A: Automation Foundation - Scheduling & Pipeline Management

*"Automation is good, so long as you know exactly where to put the machine." - Eliyahu Goldratt*

---

Welcome to the automation phase! We've built an intelligent system that can collect data and generate insights. Now it's time to make it run **automatically** - no more manual execution, no more babysitting scripts.

In this first part of Chapter 9, we'll build the scheduling and pipeline management foundation. This is the control center that orchestrates all our data collection and AI analysis on autopilot.

## üéØ What We're Building in Part A

The automation foundation includes:
- **Cron-based scheduling** system
- **Pipeline orchestration** that manages the entire workflow
- **Error handling and retries** for robust operation
- **Progress monitoring** and status reporting
- **Configuration-driven automation** that adapts to your needs

## ‚è∞ Building the Scheduler

Let's start with a flexible scheduling system, for this we'll need to install a new package:

```bash
npm install cron
```

Now let's build the scheduler:

```typescript
// lib/automation/scheduler.ts

import { CronJob } from 'cron';
import logger from '../logger';
import { ProgressTracker } from '../../utils/progress';

export interface ScheduleConfig {
  name: string;
  cronPattern: string;
  enabled: boolean;
  timezone?: string;
  maxConcurrentRuns?: number;
  retryAttempts?: number;
  retryDelayMs?: number;
}

export interface ScheduledTask {
  execute(): Promise<void>;
  getName(): string;
  getEstimatedDuration(): number; // milliseconds
}

export interface TaskExecution {
  taskName: string;
  startTime: Date;
  endTime?: Date;
  status: 'running' | 'completed' | 'failed' | 'retrying';
  error?: string;
  retryCount: number;
  executionId: string;
}

export class TaskScheduler {
  private jobs: Map<string, CronJob> = new Map();
  private runningTasks: Map<string, TaskExecution> = new Map();
  private taskHistory: TaskExecution[] = [];
  private maxHistoryItems = 100;

  /**
   * Schedule a task with cron pattern
   */
  scheduleTask(config: ScheduleConfig, task: ScheduledTask): void {
    if (this.jobs.has(config.name)) {
      logger.warn(`Task ${config.name} is already scheduled, updating...`);
      this.unscheduleTask(config.name);
    }

    if (!config.enabled) {
      logger.info(`Task ${config.name} is disabled, skipping schedule`);
      return;
    }

    const job = new CronJob(
      config.cronPattern,
      () => this.executeTask(config, task),
      null,
      true, // Start immediately
      config.timezone || 'UTC'
    );

    this.jobs.set(config.name, job);
    logger.info(`Scheduled task: ${config.name} with pattern: ${config.cronPattern}`);
  }

  /**
   * Execute a task with error handling and retries
   */
  private async executeTask(config: ScheduleConfig, task: ScheduledTask): Promise<void> {
    const executionId = this.generateExecutionId();
    const taskName = config.name;

    // Check for concurrent runs
    if (config.maxConcurrentRuns && config.maxConcurrentRuns <= 1) {
      if (this.runningTasks.has(taskName)) {
        logger.warn(`Task ${taskName} is already running, skipping execution`);
        return;
      }
    }

    const execution: TaskExecution = {
      taskName,
      startTime: new Date(),
      status: 'running',
      retryCount: 0,
      executionId
    };

    this.runningTasks.set(taskName, execution);
    logger.info(`Starting task execution: ${taskName} (${executionId})`);

    try {
      const progress = new ProgressTracker({
        total: 1,
        label: `Executing ${taskName}`
      });

      await task.execute();

      execution.status = 'completed';
      execution.endTime = new Date();
      
      const duration = execution.endTime.getTime() - execution.startTime.getTime();
      progress.complete(`Task completed in ${(duration / 1000).toFixed(2)}s`);
      
      logger.info(`Task completed successfully: ${taskName} (${executionId})`, {
        duration_ms: duration
      });

    } catch (error) {
      execution.error = error.message;
      logger.error(`Task failed: ${taskName} (${executionId})`, error);

      // Retry logic
      const maxRetries = config.retryAttempts || 0;
      if (execution.retryCount < maxRetries) {
        execution.status = 'retrying';
        execution.retryCount++;
        
        const retryDelay = config.retryDelayMs || 60000; // 1 minute default
        logger.info(`Retrying task ${taskName} in ${retryDelay}ms (attempt ${execution.retryCount}/${maxRetries})`);
        
        setTimeout(() => {
          this.executeTask(config, task);
        }, retryDelay);
        
        return;
      } else {
        execution.status = 'failed';
        execution.endTime = new Date();
      }
    } finally {
      // Clean up running tasks (unless retrying)
      if (execution.status !== 'retrying') {
        this.runningTasks.delete(taskName);
        
        // Add to history
        this.taskHistory.unshift(execution);
        if (this.taskHistory.length > this.maxHistoryItems) {
          this.taskHistory = this.taskHistory.slice(0, this.maxHistoryItems);
        }
      }
    }
  }

  /**
   * Unschedule a task
   */
  unscheduleTask(taskName: string): void {
    const job = this.jobs.get(taskName);
    if (job) {
      job.stop();
      this.jobs.delete(taskName);
      logger.info(`Unscheduled task: ${taskName}`);
    }
  }

  /**
   * Get running tasks
   */
  getRunningTasks(): TaskExecution[] {
    return Array.from(this.runningTasks.values());
  }

  /**
   * Get task history
   */
  getTaskHistory(limit?: number): TaskExecution[] {
    return limit ? this.taskHistory.slice(0, limit) : this.taskHistory;
  }

  /**
   * Get task statistics
   */
  getTaskStats(taskName?: string): any {
    const history = taskName 
      ? this.taskHistory.filter(exec => exec.taskName === taskName)
      : this.taskHistory;

    if (history.length === 0) {
      return { total_executions: 0 };
    }

    const completed = history.filter(exec => exec.status === 'completed');
    const failed = history.filter(exec => exec.status === 'failed');
    
    const completedDurations = completed
      .filter(exec => exec.endTime)
      .map(exec => exec.endTime!.getTime() - exec.startTime.getTime());

    return {
      total_executions: history.length,
      completed: completed.length,
      failed: failed.length,
      success_rate: completed.length / history.length,
      average_duration_ms: completedDurations.length > 0 
        ? completedDurations.reduce((sum, dur) => sum + dur, 0) / completedDurations.length
        : 0,
      last_execution: history[0]
    };
  }

  /**
   * Stop all scheduled tasks
   */
  stopAll(): void {
    for (const [taskName, job] of this.jobs) {
      job.stop();
      logger.info(`Stopped task: ${taskName}`);
    }
    this.jobs.clear();
  }

  /**
   * Generate unique execution ID
   */
  private generateExecutionId(): string {
    return `exec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
}

// Global scheduler instance
export const taskScheduler = new TaskScheduler();
```

## üîÑ Pipeline Orchestration

Now let's build the pipeline that coordinates our entire workflow:

```typescript
// lib/automation/digest-pipeline.ts

import { ScheduledTask } from './scheduler';
import { TwitterClient } from '../twitter/twitter-client';
import { TwitterCache } from '../twitter/twitter-cache';
import { TelegramScraper } from '../telegram/telegram-scraper';
import { TelegramCache } from '../telegram/telegram-cache';
import { RSSProcessor } from '../rss/rss-processor';
import { RSSCache } from '../rss/rss-cache';
import { AIService } from '../ai/ai-service';
import { DigestStorage } from '../digest/digest-storage';
import { SlackClient } from '../slack/slack-client';
import { ProgressTracker } from '../../utils/progress';
import logger from '../logger';

export interface DigestPipelineConfig {
  // Data collection settings
  enableTwitter: boolean;
  enableTelegram: boolean;
  enableRSS: boolean;
  
  // Processing settings
  aiModel: 'openai' | 'anthropic';
  aiModelName?: string;
  analysisType: 'digest' | 'summary' | 'market_intelligence';
  
  // Distribution settings
  postToSlack: boolean;
  slackChannelId?: string;
  
  // Quality settings
  minQualityThreshold: number;
  maxContentAge: number; // hours
}

export class DigestPipeline implements ScheduledTask {
  private config: DigestPipelineConfig;
  private twitterClient?: TwitterClient;
  private twitterCache: TwitterCache;
  private telegramScraper: TelegramScraper;
  private telegramCache: TelegramCache;
  private rssProcessor: RSSProcessor;
  private rssCache: RSSCache;
  private aiService: AIService;
  private digestStorage: DigestStorage;
  private slackClient?: SlackClient;

  constructor(config: DigestPipelineConfig) {
    this.config = config;
    
    // Initialize components based on configuration
    if (config.enableTwitter) {
      this.twitterClient = new TwitterClient();
      this.twitterCache = new TwitterCache();
    }
    
    if (config.enableTelegram) {
      this.telegramScraper = new TelegramScraper();
      this.telegramCache = new TelegramCache();
    }
    
    if (config.enableRSS) {
      this.rssProcessor = new RSSProcessor();
      this.rssCache = new RSSCache();
    }
    
    this.aiService = AIService.getInstance();
    this.digestStorage = new DigestStorage();
    
    if (config.postToSlack) {
      this.slackClient = new SlackClient();
    }
    
    // Configure AI model
    if (config.aiModel === 'openai') {
      this.aiService.useOpenAI(config.aiModelName);
    } else {
      this.aiService.useClaude(config.aiModelName);
    }
  }

  /**
   * Execute the complete digest pipeline
   */
  async execute(): Promise<void> {
    const progress = new ProgressTracker({
      total: 6,
      label: 'Digest Pipeline'
    });

    try {
      logger.info('Starting digest pipeline execution');

      // Step 1: Collect Twitter data
      progress.update(1, { step: 'Twitter Collection' });
      const tweets = await this.collectTwitterData();
      logger.info(`Collected ${tweets.length} tweets`);

      // Step 2: Collect Telegram data  
      progress.update(2, { step: 'Telegram Collection' });
      const telegramMessages = await this.collectTelegramData();
      logger.info(`Collected ${telegramMessages.length} Telegram messages`);

      // Step 3: Collect RSS data
      progress.update(3, { step: 'RSS Collection' });
      const rssArticles = await this.collectRSSData();
      logger.info(`Collected ${rssArticles.length} RSS articles`);

      // Step 4: Prepare content for AI analysis
      progress.update(4, { step: 'Content Preparation' });
      const analysisContent = this.prepareContentForAnalysis(tweets, telegramMessages, rssArticles);

      if (analysisContent.metadata.total_sources === 0) {
        logger.warn('No content collected, skipping AI analysis');
        progress.complete('Pipeline completed with no content');
        return;
      }

      // Step 5: AI Analysis
      progress.update(5, { step: 'AI Analysis' });
      const aiResponse = await this.aiService.analyzeContent({
        content: analysisContent,
        analysisType: this.config.analysisType as any
      });

      // Step 6: Store and distribute results
      progress.update(6, { step: 'Storage & Distribution' });
      const digestId = await this.storeDigest(aiResponse, analysisContent);
      
      if (this.config.postToSlack && this.slackClient) {
        await this.distributeToSlack(aiResponse, digestId);
      }

      progress.complete(`Pipeline completed successfully (Digest: ${digestId})`);
      
      logger.info('Digest pipeline completed successfully', {
        digest_id: digestId,
        content_sources: analysisContent.metadata.total_sources,
        ai_tokens_used: aiResponse.token_usage.total_tokens,
        processing_time_ms: aiResponse.processing_time_ms
      });

    } catch (error) {
      progress.fail(`Pipeline failed: ${error.message}`);
      logger.error('Digest pipeline failed', error);
      throw error;
    }
  }

  /**
   * Collect Twitter data
   */
  private async collectTwitterData(): Promise<any[]> {
    if (!this.config.enableTwitter || !this.twitterClient) {
      return [];
    }

    try {
      // Get configured Twitter accounts (you'd load this from config)
      const twitterAccounts = ['openai', 'anthropicai', 'elonmusk']; // Example
      const allTweets: any[] = [];

      for (const username of twitterAccounts) {
        try {
          // Check cache first
          const isCacheFresh = await this.twitterCache.isCacheFresh(username);
          
          let tweets;
          if (isCacheFresh) {
            tweets = await this.twitterCache.getCachedTweets(username);
            logger.debug(`Using cached tweets for @${username}: ${tweets.length} tweets`);
          } else {
            tweets = await this.twitterClient.fetchUserTweets(username);
            await this.twitterCache.storeTweets(tweets);
            logger.debug(`Fetched fresh tweets for @${username}: ${tweets.length} tweets`);
          }

          allTweets.push(...tweets);
        } catch (error) {
          logger.error(`Failed to collect tweets from @${username}`, error);
          // Continue with other accounts
        }
      }

      return this.filterByQuality(allTweets, 'tweet');
    } catch (error) {
      logger.error('Twitter data collection failed', error);
      return [];
    }
  }

  /**
   * Collect Telegram data
   */
  private async collectTelegramData(): Promise<any[]> {
    if (!this.config.enableTelegram) {
      return [];
    }

    try {
      // Get configured Telegram channels
      const telegramChannels = ['telegram', 'durov']; // Example
      const allMessages: any[] = [];

      for (const channelUsername of telegramChannels) {
        try {
          // Check cache first
          const isCacheFresh = await this.telegramCache.isCacheFresh(channelUsername);
          
          let messages;
          if (isCacheFresh) {
            messages = await this.telegramCache.getCachedMessages(channelUsername);
            logger.debug(`Using cached messages for t.me/${channelUsername}: ${messages.length} messages`);
          } else {
            const result = await this.telegramScraper.scrapeChannel(channelUsername);
            messages = result.messages;
            await this.telegramCache.storeMessages(messages);
            logger.debug(`Scraped fresh messages for t.me/${channelUsername}: ${messages.length} messages`);
          }

          allMessages.push(...messages);
        } catch (error) {
          logger.error(`Failed to collect messages from t.me/${channelUsername}`, error);
          // Continue with other channels
        }
      }

      return this.filterByQuality(allMessages, 'telegram');
    } catch (error) {
      logger.error('Telegram data collection failed', error);
      return [];
    }
  }

  /**
   * Collect RSS data
   */
  private async collectRSSData(): Promise<any[]> {
    if (!this.config.enableRSS) {
      return [];
    }

    try {
      // Get configured RSS feeds
      const rssFeeds = [
        'https://techcrunch.com/feed/',
        'https://www.theverge.com/rss/index.xml'
      ]; // Example
      
      const allArticles: any[] = [];

      for (const feedUrl of rssFeeds) {
        try {
          // Check cache first
          const isCacheFresh = await this.rssCache.isCacheFresh(feedUrl);
          
          let articles;
          if (isCacheFresh) {
            articles = await this.rssCache.getCachedArticles(feedUrl);
            logger.debug(`Using cached articles for ${feedUrl}: ${articles.length} articles`);
          } else {
            const result = await this.rssProcessor.processFeed(feedUrl);
            articles = result.articles;
            await this.rssCache.storeArticles(articles);
            logger.debug(`Processed fresh articles for ${feedUrl}: ${articles.length} articles`);
          }

          allArticles.push(...articles);
        } catch (error) {
          logger.error(`Failed to collect articles from ${feedUrl}`, error);
          // Continue with other feeds
        }
      }

      return this.filterByQuality(allArticles, 'rss');
    } catch (error) {
      logger.error('RSS data collection failed', error);
      return [];
    }
  }

  /**
   * Filter content by quality and age
   */
  private filterByQuality(content: any[], type: 'tweet' | 'telegram' | 'rss'): any[] {
    const maxAge = this.config.maxContentAge * 60 * 60 * 1000; // Convert to milliseconds
    const now = Date.now();

    return content.filter(item => {
      // Quality filter
      if (item.quality_score < this.config.minQualityThreshold) {
        return false;
      }

      // Age filter
      let itemDate: Date;
      switch (type) {
        case 'tweet':
          itemDate = new Date(item.created_at);
          break;
        case 'telegram':
          itemDate = new Date(item.message_date);
          break;
        case 'rss':
          itemDate = new Date(item.published_at || item.fetched_at);
          break;
      }

      return (now - itemDate.getTime()) <= maxAge;
    });
  }

  /**
   * Prepare content for AI analysis
   */
  private prepareContentForAnalysis(tweets: any[], telegramMessages: any[], rssArticles: any[]): any {
    const now = new Date().toISOString();
    const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString();

    return {
      tweets: tweets.map(tweet => ({
        id: tweet.id,
        text: tweet.text,
        author: tweet.author_username,
        created_at: tweet.created_at,
        engagement_score: tweet.engagement_score,
        quality_score: tweet.quality_score,
        url: tweet.source_url || `https://twitter.com/${tweet.author_username}/status/${tweet.id}`
      })),
      telegram_messages: telegramMessages.map(msg => ({
        id: msg.id,
        text: msg.text,
        channel: msg.channel_username,
        author: msg.author,
        message_date: msg.message_date,
        views: msg.views,
        quality_score: msg.quality_score,
        url: msg.source_url
      })),
      rss_articles: rssArticles.map(article => ({
        id: article.id,
        title: article.title,
        description: article.description,
        content: article.content,
        author: article.author,
        published_at: article.published_at,
        source: article.feed_title || 'RSS Feed',
        quality_score: article.quality_score,
        url: article.link
      })),
      timeframe: {
        from: oneDayAgo,
        to: now
      },
      metadata: {
        total_sources: tweets.length + telegramMessages.length + rssArticles.length,
        source_breakdown: {
          twitter: tweets.length,
          telegram: telegramMessages.length,
          rss: rssArticles.length
        }
      }
    };
  }

  /**
   * Store digest in database
   */
  private async storeDigest(aiResponse: any, analysisContent: any): Promise<string> {
    const digestData = {
      title: aiResponse.analysis.title,
      summary: aiResponse.analysis.executive_summary,
      content: aiResponse.analysis,
      ai_model: aiResponse.model_info.model,
      ai_provider: aiResponse.model_info.provider,
      token_usage: aiResponse.token_usage,
      data_from: analysisContent.timeframe.from,
      data_to: analysisContent.timeframe.to,
      published_to_slack: false,
      created_at: new Date().toISOString(),
      updated_at: new Date().toISOString()
    };

    return await this.digestStorage.storeDigest(digestData);
  }

  /**
   * Distribute to Slack
   */
  private async distributeToSlack(aiResponse: any, digestId: string): Promise<void> {
    if (!this.slackClient) return;

    try {
      await this.slackClient.postDigest({
        title: aiResponse.analysis.title,
        summary: aiResponse.analysis.executive_summary,
        tweets: [], // You'd format these properly
        articles: [],
        metadata: {
          digest_id: digestId,
          ai_model: aiResponse.model_info.model,
          token_usage: aiResponse.token_usage
        }
      });

      // Update digest as posted to Slack
      await this.digestStorage.updateDigest(digestId, { published_to_slack: true });
      
      logger.info(`Digest distributed to Slack: ${digestId}`);
    } catch (error) {
      logger.error('Failed to distribute to Slack', error);
      // Don't throw - we still want the digest to be considered successful
    }
  }

  /**
   * Get task name for scheduler
   */
  getName(): string {
    return 'digest-pipeline';
  }

  /**
   * Get estimated duration in milliseconds
   */
  getEstimatedDuration(): number {
    return 5 * 60 * 1000; // 5 minutes
  }
}
```

## üíæ Digest Storage System

Before we can use the pipeline, we need the DigestStorage component and update our `envConfig`.

Your updated `envConfig` should include youre supabase secrets from earlier:

```typescript
// config/environment.ts

export interface EnvironmentConfig {
  development: boolean;
  supabaseUrl: string;
  supabaseServiceKey: string;
  apiTimeouts: {
    twitter: number;
    telegram: number;
    rss: number;
  };
  logging: {
    level: string;
    enableConsole: boolean;
  };
  rateLimit: {
    respectLimits: boolean;
    bufferTimeMs: number;
  };
}

function getEnvironmentConfig(): EnvironmentConfig {
  const isDev = process.env.NODE_ENV === 'development';
  
  return {
    development: isDev,
    supabaseUrl: process.env.NEXT_PUBLIC_SUPABASE_URL || '',
    supabaseServiceKey: process.env.SUPABASE_SERVICE_ROLE_KEY || '',
    
    apiTimeouts: {
      twitter: isDev ? 10000 : 30000,    // Shorter timeouts in dev
      telegram: isDev ? 15000 : 45000,
      rss: isDev ? 5000 : 15000,
    },
    
    logging: {
      level: isDev ? 'debug' : 'info',
      enableConsole: isDev,
    },
    
    rateLimit: {
      respectLimits: true,
      bufferTimeMs: isDev ? 1000 : 5000,  // Less aggressive in dev
    }
  };
}
  
export const envConfig = getEnvironmentConfig();
```

Now for the digest-storage to record and retreive our A.I. output from supabase:

```typescript
// lib/digest/digest-storage.ts

import { createClient } from '@supabase/supabase-js';
import { envConfig } from '../../config/environment';
import logger from '../logger';

export interface DigestData {
  title: string;
  summary: string;
  content: any;
  ai_model: string;
  ai_provider: string;
  token_usage: any;
  data_from: string;
  data_to: string;
  published_to_slack: boolean;
  created_at: string;
  updated_at: string;
}

export class DigestStorage {
  private supabase = createClient(envConfig.supabaseUrl, envConfig.supabaseServiceKey);

  /**
   * Store a new digest in the database
   */
  async storeDigest(digestData: DigestData): Promise<string> {
    try {
      const { data, error } = await this.supabase
        .from('digests')
        .insert({
          ...digestData,
          id: this.generateDigestId()
        })
        .select('id')
        .single();

      if (error) {
        throw error;
      }

      logger.info('Digest stored successfully', { digest_id: data.id });
      return data.id;

    } catch (error) {
      logger.error('Failed to store digest', error);
      throw error;
    }
  }

  /**
   * Update an existing digest
   */
  async updateDigest(digestId: string, updates: Partial<DigestData>): Promise<void> {
    try {
      const { error } = await this.supabase
        .from('digests')
        .update({
          ...updates,
          updated_at: new Date().toISOString()
        })
        .eq('id', digestId);

      if (error) {
        throw error;
      }

      logger.info('Digest updated successfully', { digest_id: digestId });

    } catch (error) {
      logger.error('Failed to update digest', error);
      throw error;
    }
  }

  /**
   * Get recent digests
   */
  async getRecentDigests(limit: number = 10): Promise<any[]> {
    try {
      const { data, error } = await this.supabase
        .from('digests')
        .select('*')
        .order('created_at', { ascending: false })
        .limit(limit);

      if (error) {
        throw error;
      }

      return data || [];

    } catch (error) {
      logger.error('Failed to get recent digests', error);
      throw error;
    }
  }

  /**
   * Get digest by ID
   */
  async getDigest(digestId: string): Promise<any> {
    try {
      const { data, error } = await this.supabase
        .from('digests')
        .select('*')
        .eq('id', digestId)
        .single();

      if (error) {
        throw error;
      }

      return data;

    } catch (error) {
      logger.error('Failed to get digest', error);
      throw error;
    }
  }

  private generateDigestId(): string {
    return `digest_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
}
```

## üí¨ Basic Slack Client

Here's the basic SlackClient that the pipeline uses:

```typescript
// lib/slack/slack-client.ts

import { WebClient } from '@slack/web-api';
import logger from '../logger';

export interface SlackDigestData {
  title: string;
  summary: string;
  tweets: any[];
  articles: any[];
  metadata: {
    digest_id: string;
    ai_model: string;
    token_usage: any;
  };
}

export class SlackClient {
  private client: WebClient;
  private defaultChannel: string;

  constructor() {
    this.client = new WebClient(process.env.SLACK_BOT_TOKEN);
    this.defaultChannel = process.env.SLACK_CHANNEL_ID || '#general';
  }

  /**
   * Post digest to Slack channel
   */
  async postDigest(digestData: SlackDigestData, channelId?: string): Promise<void> {
    try {
      const channel = channelId || this.defaultChannel;
      const blocks = this.buildDigestBlocks(digestData);

      const result = await this.client.chat.postMessage({
        channel: channel,
        text: `New Digest: ${digestData.title}`,
        blocks: blocks
      });

      logger.info('Digest posted to Slack', {
        digest_id: digestData.metadata.digest_id,
        channel: channel,
        message_ts: result.ts
      });

    } catch (error) {
      logger.error('Failed to post digest to Slack', error);
      throw error;
    }
  }

  /**
   * Send simple message to Slack
   */
  async sendMessage(text: string, channelId?: string): Promise<void> {
    try {
      const channel = channelId || this.defaultChannel;

      await this.client.chat.postMessage({
        channel: channel,
        text: text
      });

      logger.info('Message sent to Slack', { channel, text: text.substring(0, 50) });

    } catch (error) {
      logger.error('Failed to send message to Slack', error);
      throw error;
    }
  }

  /**
   * Build Slack blocks for digest
   */
  private buildDigestBlocks(digestData: SlackDigestData): any[] {
    const blocks = [
      {
        type: 'header',
        text: {
          type: 'plain_text',
          text: digestData.title
        }
      },
      {
        type: 'section',
        text: {
          type: 'mrkdwn',
          text: `*Summary:*\n${digestData.summary}`
        }
      },
      {
        type: 'divider'
      }
    ];

    // Add tweet highlights if available
    if (digestData.tweets && digestData.tweets.length > 0) {
      blocks.push({
        type: 'section',
        text: {
          type: 'mrkdwn',
          text: '*üê¶ Tweet Highlights:*'
        }
      });

      digestData.tweets.slice(0, 3).forEach(tweet => {
        blocks.push({
          type: 'section',
          text: {
            type: 'mrkdwn',
            text: `‚Ä¢ ${tweet.text.substring(0, 100)}... - @${tweet.author}`
          }
        });
      });

      blocks.push({ type: 'divider' });
    }

    // Add article highlights if available
    if (digestData.articles && digestData.articles.length > 0) {
      blocks.push({
        type: 'section',
        text: {
          type: 'mrkdwn',
          text: '*üì∞ Article Highlights:*'
        }
      });

      digestData.articles.slice(0, 3).forEach(article => {
        blocks.push({
          type: 'section',
          text: {
            type: 'mrkdwn',
            text: `‚Ä¢ <${article.url}|${article.title}>\n  ${article.description?.substring(0, 100)}...`
          }
        });
      });

      blocks.push({ type: 'divider' });
    }

    // Add metadata
    blocks.push({
      type: 'context',
      elements: [
        {
          type: 'mrkdwn',
          text: `ü§ñ Generated by ${digestData.metadata.ai_model} ‚Ä¢ Digest ID: ${digestData.metadata.digest_id}`
        }
      ]
    });

    return blocks;
  }

  /**
   * Test Slack connection
   */
  async testConnection(): Promise<boolean> {
    try {
      const result = await this.client.auth.test();
      logger.info('Slack connection test successful', { team: result.team, user: result.user });
      return true;
    } catch (error) {
      logger.error('Slack connection test failed', error);
      return false;
    }
  }
}
```

## üéØ Package Dependencies

Make sure to install the required packages:

```bash
npm install @slack/web-api @slack/bolt cron
npm install --save-dev @types/cron
```

This completes Part A of Chapter 9. In Part B, we'll cover:
- Error handling and monitoring systems
- Configuration management for automation
- Testing the automation pipeline
- Production scheduling examples

# Chapter 9B: Monitoring & Configuration - Making Automation Bulletproof

*"In God we trust. All others must bring data." - W. Edwards Deming*

---

Now that we have our automation foundation, let's make it bulletproof! This part focuses on monitoring, error handling, and configuration management - the operational excellence that separates hobby projects from production systems.

## üéØ What We're Building in Part B

Advanced monitoring and configuration including:
- **Health monitoring system** with alerts
- **Error tracking and analysis** 
- **Configuration management** for different environments
- **Performance metrics** and optimization insights
- **Automated recovery** from common failures

## üìä Health Monitoring System

Let's build a comprehensive health monitoring system:

```typescript
// lib/automation/health-monitor.ts

import { EventEmitter } from 'events';
import logger from '../logger';

export interface HealthMetric {
  name: string;
  value: number;
  threshold: number;
  status: 'healthy' | 'warning' | 'critical';
  lastUpdated: Date;
  trend: 'improving' | 'stable' | 'degrading';
}

export interface SystemHealth {
  overall_status: 'healthy' | 'warning' | 'critical';
  metrics: HealthMetric[];
  last_successful_run?: Date;
  uptime_hours: number;
  error_rate: number;
}

export interface AlertRule {
  metricName: string;
  condition: 'above' | 'below' | 'equals';
  threshold: number;
  severity: 'warning' | 'critical';
  enabled: boolean;
  cooldownMinutes: number;
}

export class HealthMonitor extends EventEmitter {
  private metrics: Map<string, HealthMetric> = new Map();
  private alertRules: AlertRule[] = [];
  private alertHistory: Map<string, Date> = new Map();
  private startTime: Date = new Date();
  private errorCount: number = 0;
  private totalRuns: number = 0;

  constructor() {
    super();
    this.initializeDefaultMetrics();
    this.initializeDefaultAlerts();
    this.startPeriodicHealthCheck();
  }

  /**
   * Initialize default health metrics
   */
  private initializeDefaultMetrics(): void {
    const defaultMetrics = [
      { name: 'pipeline_success_rate', value: 100, threshold: 90 },
      { name: 'avg_execution_time_minutes', value: 0, threshold: 10 },
      { name: 'twitter_api_calls_per_hour', value: 0, threshold: 100 },
      { name: 'ai_token_usage_per_day', value: 0, threshold: 50000 },
      { name: 'cache_hit_rate', value: 0, threshold: 70 },
      { name: 'error_rate_percentage', value: 0, threshold: 5 },
      { name: 'data_freshness_hours', value: 0, threshold: 6 }
    ];

    defaultMetrics.forEach(metric => {
      this.updateMetric(metric.name, metric.value, metric.threshold);
    });
  }

  /**
   * Initialize default alert rules
   */
  private initializeDefaultAlerts(): void {
    this.alertRules = [
      {
        metricName: 'pipeline_success_rate',
        condition: 'below',
        threshold: 80,
        severity: 'critical',
        enabled: true,
        cooldownMinutes: 60
      },
      {
        metricName: 'avg_execution_time_minutes',
        condition: 'above',
        threshold: 15,
        severity: 'warning',
        enabled: true,
        cooldownMinutes: 30
      },
      {
        metricName: 'ai_token_usage_per_day',
        condition: 'above',
        threshold: 75000,
        severity: 'warning',
        enabled: true,
        cooldownMinutes: 240
      },
      {
        metricName: 'error_rate_percentage',
        condition: 'above',
        threshold: 10,
        severity: 'critical',
        enabled: true,
        cooldownMinutes: 30
      }
    ];
  }

  /**
   * Update a health metric
   */
  updateMetric(name: string, value: number, threshold?: number): void {
    const existing = this.metrics.get(name);
    const now = new Date();

    // Calculate trend
    let trend: 'improving' | 'stable' | 'degrading' = 'stable';
    if (existing) {
      const diff = value - existing.value;
      const isPositiveMetric = ['success_rate', 'cache_hit_rate'].some(pos => name.includes(pos));
      
      if (Math.abs(diff) > existing.value * 0.1) { // 10% change threshold
        if (isPositiveMetric) {
          trend = diff > 0 ? 'improving' : 'degrading';
        } else {
          trend = diff < 0 ? 'improving' : 'degrading';
        }
      }
    }

    // Determine status
    const metricThreshold = threshold || existing?.threshold || 0;
    let status: 'healthy' | 'warning' | 'critical' = 'healthy';
    
    if (name.includes('rate') || name.includes('percentage')) {
      // For rates/percentages, lower values might be bad
      if (name.includes('success') || name.includes('hit')) {
        if (value < metricThreshold * 0.8) status = 'critical';
        else if (value < metricThreshold) status = 'warning';
      } else {
        if (value > metricThreshold * 1.5) status = 'critical';
        else if (value > metricThreshold) status = 'warning';
      }
    } else {
      // For other metrics, higher values are usually bad
      if (value > metricThreshold * 1.5) status = 'critical';
      else if (value > metricThreshold) status = 'warning';
    }

    const metric: HealthMetric = {
      name,
      value,
      threshold: metricThreshold,
      status,
      lastUpdated: now,
      trend
    };

    this.metrics.set(name, metric);

    // Check for alerts
    this.checkAlerts(metric);

    logger.debug(`Health metric updated: ${name} = ${value} (${status})`);
  }

  /**
   * Check alert rules for a metric
   */
  private checkAlerts(metric: HealthMetric): void {
    const applicableRules = this.alertRules.filter(rule => 
      rule.metricName === metric.name && rule.enabled
    );

    for (const rule of applicableRules) {
      const shouldAlert = this.evaluateAlertCondition(metric.value, rule);
      
      if (shouldAlert && this.canSendAlert(rule)) {
        this.sendAlert(rule, metric);
      }
    }
  }

  /**
   * Evaluate if alert condition is met
   */
  private evaluateAlertCondition(value: number, rule: AlertRule): boolean {
    switch (rule.condition) {
      case 'above':
        return value > rule.threshold;
      case 'below':
        return value < rule.threshold;
      case 'equals':
        return value === rule.threshold;
      default:
        return false;
    }
  }

  /**
   * Check if we can send alert (cooldown logic)
   */
  private canSendAlert(rule: AlertRule): boolean {
    const alertKey = `${rule.metricName}_${rule.severity}`;
    const lastAlert = this.alertHistory.get(alertKey);
    
    if (!lastAlert) return true;
    
    const cooldownMs = rule.cooldownMinutes * 60 * 1000;
    return (Date.now() - lastAlert.getTime()) > cooldownMs;
  }

  /**
   * Send alert
   */
  private sendAlert(rule: AlertRule, metric: HealthMetric): void {
    const alertKey = `${rule.metricName}_${rule.severity}`;
    this.alertHistory.set(alertKey, new Date());

    const alertData = {
      severity: rule.severity,
      metric: metric.name,
      value: metric.value,
      threshold: rule.threshold,
      condition: rule.condition,
      status: metric.status,
      trend: metric.trend
    };

    // Emit alert event
    this.emit('alert', alertData);

    logger.warn(`Health alert: ${rule.severity.toUpperCase()}`, alertData);

    // You could integrate with external services here:
    // - Send to Slack
    // - Send email
    // - Post to monitoring service (DataDog, New Relic, etc.)
  }

  /**
   * Record pipeline execution
   */
  recordPipelineExecution(success: boolean, durationMs: number, tokenUsage?: number): void {
    this.totalRuns++;
    if (!success) this.errorCount++;

    // Update success rate
    const successRate = ((this.totalRuns - this.errorCount) / this.totalRuns) * 100;
    this.updateMetric('pipeline_success_rate', successRate, 90);

    // Update average execution time
    const durationMinutes = durationMs / (1000 * 60);
    this.updateMetric('avg_execution_time_minutes', durationMinutes, 10);

    // Update error rate
    const errorRate = (this.errorCount / this.totalRuns) * 100;
    this.updateMetric('error_rate_percentage', errorRate, 5);

    // Update token usage if provided
    if (tokenUsage) {
      // This would typically be accumulated over time
      this.updateMetric('ai_token_usage_per_day', tokenUsage, 50000);
    }
  }

  /**
   * Get current system health
   */
  getSystemHealth(): SystemHealth {
    const metrics = Array.from(this.metrics.values());
    
    // Determine overall status
    let overallStatus: 'healthy' | 'warning' | 'critical' = 'healthy';
    const criticalMetrics = metrics.filter(m => m.status === 'critical');
    const warningMetrics = metrics.filter(m => m.status === 'warning');
    
    if (criticalMetrics.length > 0) {
      overallStatus = 'critical';
    } else if (warningMetrics.length > 0) {
      overallStatus = 'warning';
    }

    // Calculate uptime
    const uptimeMs = Date.now() - this.startTime.getTime();
    const uptimeHours = uptimeMs / (1000 * 60 * 60);

    return {
      overall_status: overallStatus,
      metrics: metrics.sort((a, b) => a.name.localeCompare(b.name)),
      uptime_hours: Math.round(uptimeHours * 100) / 100,
      error_rate: this.totalRuns > 0 ? (this.errorCount / this.totalRuns) * 100 : 0
    };
  }

  /**
   * Start periodic health checks
   */
  private startPeriodicHealthCheck(): void {
    setInterval(() => {
      this.performHealthCheck();
    }, 5 * 60 * 1000); // Every 5 minutes
  }

  /**
   * Perform comprehensive health check
   */
  private performHealthCheck(): void {
    // Check data freshness
    this.checkDataFreshness();
    
    // Check system resources if possible
    this.checkSystemResources();
    
    // Emit health check complete event
    this.emit('healthcheck', this.getSystemHealth());
  }

  /**
   * Check data freshness across sources
   */
  private async checkDataFreshness(): Promise<void> {
    try {
      // This would check when data was last updated
      // For now, we'll simulate
      const hoursOld = Math.random() * 12; // 0-12 hours
      this.updateMetric('data_freshness_hours', hoursOld, 6);
    } catch (error) {
      logger.error('Data freshness check failed', error);
    }
  }

  /**
   * Check system resources
   */
  private checkSystemResources(): void {
    try {
      // Memory usage
      const memUsage = process.memoryUsage();
      const memUsedMB = memUsage.heapUsed / 1024 / 1024;
      this.updateMetric('memory_usage_mb', Math.round(memUsedMB), 500);

      // CPU usage would require additional libraries
      // For now, we'll use a placeholder
      this.updateMetric('cpu_usage_percentage', Math.random() * 30, 80);
      
    } catch (error) {
      logger.error('System resource check failed', error);
    }
  }

  /**
   * Get metrics history (for trending)
   */
  getMetricsHistory(metricName: string, hours: number = 24): any[] {
    // In a real implementation, you'd store historical data
    // For now, return mock data
    const history = [];
    const now = Date.now();
    const hourMs = 60 * 60 * 1000;
    
    for (let i = hours; i >= 0; i--) {
      history.push({
        timestamp: new Date(now - (i * hourMs)),
        value: Math.random() * 100 // Mock data
      });
    }
    
    return history;
  }
}

// Global health monitor instance
export const healthMonitor = new HealthMonitor();
```

## ‚öôÔ∏è Advanced Configuration Management

Now let's build a flexible configuration system for different environments:

```typescript
// lib/automation/config-manager.ts

import { readFileSync, writeFileSync } from 'fs';
import { join } from 'path';
import logger from '../logger';

export interface AutomationConfig {
  environment: 'development' | 'staging' | 'production';
  
  // Scheduling configuration
  scheduling: {
    digest_pipeline: {
      enabled: boolean;
      cron_pattern: string;
      timezone: string;
      max_concurrent_runs: number;
      retry_attempts: number;
      retry_delay_ms: number;
    };
    cache_cleanup: {
      enabled: boolean;
      cron_pattern: string;
      retention_days: number;
    };
    health_check: {
      enabled: boolean;
      interval_minutes: number;
    };
  };

  // Data source configuration
  data_sources: {
    twitter: {
      enabled: boolean;
      accounts: string[];
      api_rate_limit_buffer: number;
    };
    telegram: {
      enabled: boolean;
      channels: string[];
      scraping_delay_ms: number;
    };
    rss: {
      enabled: boolean;
      feeds: string[];
      timeout_ms: number;
    };
  };

  // AI configuration
  ai: {
    default_provider: 'openai' | 'anthropic';
    model_configs: {
      routine: {
        provider: 'openai' | 'anthropic';
        model: string;
        max_tokens: number;
        temperature: number;
      };
      important: {
        provider: 'openai' | 'anthropic';
        model: string;
        max_tokens: number;
        temperature: number;
      };
      critical: {
        provider: 'openai' | 'anthropic';
        model: string;
        max_tokens: number;
        temperature: number;
      };
    };
    cost_limits: {
      daily_budget: number;
      per_analysis_limit: number;
    };
  };

  // Quality and filtering
  quality: {
    min_quality_threshold: number;
    max_content_age_hours: number;
    min_engagement_threshold: number;
  };

  // Distribution configuration
  distribution: {
    slack: {
      enabled: boolean;
      channel_id: string;
      webhook_url?: string;
    };
    webhook_notifications: {
      enabled: boolean;
      endpoints: string[];
    };
  };

  // Monitoring and alerts
  monitoring: {
    health_checks: boolean;
    alert_webhooks: string[];
    log_level: 'debug' | 'info' | 'warn' | 'error';
    metrics_retention_days: number;
  };
}

export class ConfigManager {
  private config!: AutomationConfig;
  private configPath: string;
  private watchers: ((config: AutomationConfig) => void)[] = [];

  constructor(configPath?: string) {
    this.configPath = configPath || join(process.cwd(), 'config', 'automation.json');
    this.loadConfig();
  }

  /**
   * Load configuration from file
   */
  private loadConfig(): void {
    try {
      const configData = readFileSync(this.configPath, 'utf-8');
      this.config = JSON.parse(configData);
      this.validateConfig();
      logger.info(`Configuration loaded from ${this.configPath}`);
    } catch (error) {
      logger.warn(`Failed to load config from ${this.configPath}, using defaults`);
      this.config = this.getDefaultConfig();
      this.saveConfig(); // Create default config file
    }
  }

  /**
   * Get default configuration
   */
  private getDefaultConfig(): AutomationConfig {
    const isDev = process.env.NODE_ENV === 'development';
    
    return {
      environment: isDev ? 'development' : 'production',
      
      scheduling: {
        digest_pipeline: {
          enabled: true,
          cron_pattern: isDev ? '*/15 * * * *' : '0 9 * * *', // Every 15 min in dev, 9 AM in prod
          timezone: 'UTC',
          max_concurrent_runs: 1,
          retry_attempts: 3,
          retry_delay_ms: 60000
        },
        cache_cleanup: {
          enabled: true,
          cron_pattern: '0 2 * * *', // 2 AM daily
          retention_days: 7
        },
        health_check: {
          enabled: true,
          interval_minutes: 5
        }
      },

      data_sources: {
        twitter: {
          enabled: !!process.env.X_API_KEY,
          accounts: ['openai', 'anthropicai'],
          api_rate_limit_buffer: 5000
        },
        telegram: {
          enabled: true,
          channels: ['telegram', 'durov'],
          scraping_delay_ms: isDev ? 2000 : 5000
        },
        rss: {
          enabled: true,
          feeds: [
            'https://techcrunch.com/feed/',
            'https://www.theverge.com/rss/index.xml'
          ],
          timeout_ms: 15000
        }
      },

      ai: {
        default_provider: 'anthropic',
        model_configs: {
          routine: {
            provider: 'openai',
            model: 'gpt-4o-mini',
            max_tokens: 1500,
            temperature: 0.7
          },
          important: {
            provider: 'anthropic',
            model: 'claude-3-5-sonnet-20241022',
            max_tokens: 2000,
            temperature: 0.7
          },
          critical: {
            provider: 'anthropic',
            model: 'claude-3-5-sonnet-20241022',
            max_tokens: 3000,
            temperature: 0.3
          }
        },
        cost_limits: {
          daily_budget: isDev ? 1.0 : 10.0,
          per_analysis_limit: isDev ? 0.25 : 2.0
        }
      },

      quality: {
        min_quality_threshold: 0.6,
        max_content_age_hours: 24,
        min_engagement_threshold: 5
      },

      distribution: {
        slack: {
          enabled: !!process.env.SLACK_BOT_TOKEN,
          channel_id: process.env.SLACK_CHANNEL_ID || ''
        },
        webhook_notifications: {
          enabled: false,
          endpoints: []
        }
      },

      monitoring: {
        health_checks: true,
        alert_webhooks: [],
        log_level: isDev ? 'debug' : 'info',
        metrics_retention_days: 30
      }
    };
  }

  /**
   * Validate configuration
   */
  private validateConfig(): void {
    const requiredPaths = [
      'environment',
      'scheduling.digest_pipeline.cron_pattern',
      'ai.default_provider',
      'quality.min_quality_threshold'
    ];

    for (const path of requiredPaths) {
      if (!this.getNestedValue(this.config, path)) {
        throw new Error(`Missing required configuration: ${path}`);
      }
    }

    // Validate cron patterns
    const cronPatterns = [
      this.config.scheduling.digest_pipeline.cron_pattern,
      this.config.scheduling.cache_cleanup.cron_pattern
    ];

    for (const pattern of cronPatterns) {
      if (!this.isValidCronPattern(pattern)) {
        logger.warn(`Invalid cron pattern: ${pattern}`);
      }
    }

    logger.debug('Configuration validation passed');
  }

  /**
   * Get nested configuration value
   */
  private getNestedValue(obj: any, path: string): any {
    return path.split('.').reduce((current, key) => current?.[key], obj);
  }

  /**
   * Basic cron pattern validation
   */
  private isValidCronPattern(pattern: string): boolean {
    const parts = pattern.split(' ');
    return parts.length === 5 || parts.length === 6; // 5 for standard, 6 with seconds
  }

  /**
   * Get current configuration
   */
  getConfig(): AutomationConfig {
    return { ...this.config }; // Return copy to prevent mutations
  }

  /**
   * Update configuration
   */
  updateConfig(updates: Partial<AutomationConfig>): void {
    this.config = { ...this.config, ...updates };
    this.validateConfig();
    this.saveConfig();
    this.notifyWatchers();
  }

  /**
   * Save configuration to file
   */
  private saveConfig(): void {
    try {
      const configData = JSON.stringify(this.config, null, 2);
      writeFileSync(this.configPath, configData, 'utf-8');
      logger.info(`Configuration saved to ${this.configPath}`);
    } catch (error) {
      logger.error('Failed to save configuration', error);
    }
  }

  /**
   * Watch for configuration changes
   */
  watch(callback: (config: AutomationConfig) => void): void {
    this.watchers.push(callback);
  }

  /**
   * Notify watchers of configuration changes
   */
  private notifyWatchers(): void {
    for (const watcher of this.watchers) {
      try {
        watcher(this.getConfig());
      } catch (error) {
        logger.error('Configuration watcher error', error);
      }
    }
  }

  /**
   * Get environment-specific settings
   */
  getEnvironmentConfig(): any {
    const env = this.config.environment;
    
    return {
      isDevelopment: env === 'development',
      isProduction: env === 'production',
      logLevel: this.config.monitoring.log_level,
      enableDebugFeatures: env === 'development',
      enablePerformanceMetrics: env === 'production',
      strictErrorHandling: env === 'production'
    };
  }

  /**
   * Validate required environment variables
   */
  validateEnvironment(): { valid: boolean; missing: string[] } {
    const required: { [key: string]: string[] } = {
      all: ['NODE_ENV'],
      twitter: ['X_API_KEY', 'X_API_SECRET'],
      ai: ['OPENAI_API_KEY', 'ANTHROPIC_API_KEY'],
      slack: ['SLACK_BOT_TOKEN', 'SLACK_CHANNEL_ID']
    };

    const missing: string[] = [];

    // Check all environments
    for (const envVar of required.all) {
      if (!process.env[envVar]) {
        missing.push(envVar);
      }
    }

    // Check conditionally required
    if (this.config.data_sources.twitter.enabled) {
      for (const envVar of required.twitter) {
        if (!process.env[envVar]) {
          missing.push(envVar);
        }
      }
    }

    if (this.config.distribution.slack.enabled) {
      for (const envVar of required.slack) {
        if (!process.env[envVar]) {
          missing.push(envVar);
        }
      }
    }

    // Check AI keys (at least one required)
    const hasOpenAI = !!process.env.OPENAI_API_KEY;
    const hasAnthropic = !!process.env.ANTHROPIC_API_KEY;
    
    if (!hasOpenAI && !hasAnthropic) {
      missing.push('OPENAI_API_KEY or ANTHROPIC_API_KEY');
    }

    return {
      valid: missing.length === 0,
      missing
    };
  }
}

// Global configuration manager
export const configManager = new ConfigManager();
```

This completes Part B with monitoring and configuration systems. Ready for **Part C** which will cover:
- **Testing the complete automation system**
- **Production deployment setup**
- **Performance optimization**
- **Troubleshooting guide**

# Chapter 9C: Testing & Optimization - Bulletproofing Your Automation

*"The most important single aspect of software development is to be clear about what you are trying to build." - Bjarne Stroustrup*

---

Time to put it all together! In this final part of Chapter 9, we'll test our complete automation system, optimize performance, and build the production deployment setup. This is where we ensure everything works flawlessly when you're not watching.

## üéØ What We're Building in Part C

The final automation pieces:
- **Complete integration testing** suite
- **Performance optimization** and bottleneck detection
- **Production deployment scripts**
- **Troubleshooting and debugging** toolkit
- **Monitoring dashboard** for operational visibility

## üß™ Complete Integration Testing Suite

Let's build comprehensive tests for the entire automation system:

```typescript
// scripts/test/test-automation-complete.ts

import { config } from 'dotenv';
config({ path: '.env.local' });

import { taskScheduler, ScheduleConfig } from '../../lib/automation/scheduler';
import { DigestPipeline } from '../../lib/automation/digest-pipeline';
import { healthMonitor } from '../../lib/automation/health-monitor';
import { configManager } from '../../lib/automation/config-manager';
import { ProgressTracker } from '../../utils/progress';
import logger from '../../lib/logger';

class AutomationTestSuite {
  private testResults: Map<string, boolean> = new Map();
  private testStartTime: number = 0;

  async runCompleteTest(): Promise<void> {
    console.log('ü§ñ Testing Complete Automation System...\n');
    
    const overallProgress = new ProgressTracker({
      total: 8,
      label: 'Complete Automation Test'
    });

    this.testStartTime = Date.now();

    try {
      // Test 1: Configuration Management
      overallProgress.update(1, { step: 'Configuration' });
      await this.testConfigurationSystem();

      // Test 2: Health Monitoring
      overallProgress.update(2, { step: 'Health Monitoring' });
      await this.testHealthMonitoring();

      // Test 3: Pipeline Components
      overallProgress.update(3, { step: 'Pipeline Components' });
      await this.testPipelineComponents();

      // Test 4: Scheduler Functionality  
      overallProgress.update(4, { step: 'Scheduler' });
      await this.testScheduler();

      // Test 5: Error Handling
      overallProgress.update(5, { step: 'Error Handling' });
      await this.testErrorHandling();

      // Test 6: Performance Benchmarks
      overallProgress.update(6, { step: 'Performance' });
      await this.testPerformance();

      // Test 7: End-to-End Pipeline
      overallProgress.update(7, { step: 'End-to-End' });
      await this.testEndToEndPipeline();

      // Test 8: Production Readiness
      overallProgress.update(8, { step: 'Production Readiness' });
      await this.testProductionReadiness();

      // Summary
      const totalTime = Date.now() - this.testStartTime;
      overallProgress.complete(`All tests completed in ${(totalTime / 1000).toFixed(2)}s`);
      
      this.printTestSummary();

    } catch (error: any) {
      overallProgress.fail(`Test suite failed: ${error.message}`);
      logger.error('Automation test suite failed', error);
      throw error;
    }
  }

  /**
   * Test configuration management system
   */
  private async testConfigurationSystem(): Promise<void> {
    try {
      console.log('1. Testing Configuration Management:');

      // Test config loading
      const config = configManager.getConfig();
      console.log(`   ‚úÖ Configuration loaded: ${config.environment} environment`);

      // Test environment validation
      const envValidation = configManager.validateEnvironment();
      if (envValidation.valid) {
        console.log('   ‚úÖ Environment variables validated');
      } else {
        console.log(`   ‚ö†Ô∏è  Missing environment variables: ${envValidation.missing.join(', ')}`);
      }

      // Test environment-specific settings
      const envConfig = configManager.getEnvironmentConfig();
      console.log(`   ‚úÖ Environment config loaded: ${envConfig.isDevelopment ? 'Development' : 'Production'} mode`);

      // Test configuration update
      const originalLogLevel = config.monitoring.log_level;
      configManager.updateConfig({
        monitoring: { ...config.monitoring, log_level: 'debug' }
      });
      
      const updatedConfig = configManager.getConfig();
      const updateSuccessful = updatedConfig.monitoring.log_level === 'debug';
      
      // Restore original
      configManager.updateConfig({
        monitoring: { ...config.monitoring, log_level: originalLogLevel }
      });

      if (updateSuccessful) {
        console.log('   ‚úÖ Configuration update successful');
      } else {
        throw new Error('Configuration update failed');
      }

      this.testResults.set('configuration', true);

    } catch (error: any) {
      console.log(`   ‚ùå Configuration test failed: ${error.message}`);
      this.testResults.set('configuration', false);
    }
  }

  /**
   * Test health monitoring system
   */
  private async testHealthMonitoring(): Promise<void> {
    try {
      console.log('\n2. Testing Health Monitoring:');

      // Test metric updates
      healthMonitor.updateMetric('test_metric', 85, 90);
      console.log('   ‚úÖ Health metric update successful');

      // Test pipeline execution recording
      healthMonitor.recordPipelineExecution(true, 120000, 5000); // 2 min, 5k tokens
      console.log('   ‚úÖ Pipeline execution recorded');

      // Test system health retrieval
      const systemHealth = healthMonitor.getSystemHealth();
      console.log(`   ‚úÖ System health: ${systemHealth.overall_status} (${systemHealth.metrics.length} metrics)`);
      console.log(`   ‚úÖ Uptime: ${systemHealth.uptime_hours.toFixed(2)} hours`);
      console.log(`   ‚úÖ Error rate: ${systemHealth.error_rate.toFixed(1)}%`);

      // Test alert system (simulate)
      let alertReceived = false;
      healthMonitor.once('alert', (alertData) => {
        alertReceived = true;
        console.log(`   ‚úÖ Alert system working: ${alertData.severity} alert for ${alertData.metric}`);
      });

      // Trigger an alert with a bad metric
      healthMonitor.updateMetric('pipeline_success_rate', 50, 90); // Should trigger critical alert
      
      // Wait briefly for alert
      await new Promise(resolve => setTimeout(resolve, 100));
      
      if (alertReceived) {
        console.log('   ‚úÖ Alert system functional');
      } else {
        console.log('   ‚ö†Ô∏è  Alert system may not be working');
      }

      // Reset metric
      healthMonitor.updateMetric('pipeline_success_rate', 95, 90);

      this.testResults.set('health_monitoring', true);

    } catch (error: any) {
      console.log(`   ‚ùå Health monitoring test failed: ${error.message}`);
      this.testResults.set('health_monitoring', false);
    }
  }

  /**
   * Test individual pipeline components
   */
  private async testPipelineComponents(): Promise<void> {
    try {
      console.log('\n3. Testing Pipeline Components:');

      const config = configManager.getConfig();
      
      // Create pipeline instance
      const pipeline = new DigestPipeline({
        enableTwitter: config.data_sources.twitter.enabled,
        enableTelegram: config.data_sources.telegram.enabled,
        enableRSS: config.data_sources.rss.enabled,
        aiModel: config.ai.default_provider,
        aiModelName: config.ai.model_configs.routine.model,
        analysisType: 'summary',
        postToSlack: false, // Don't actually post during testing
        minQualityThreshold: 0.5, // Lower for testing
        maxContentAge: 48 // More lenient for testing
      });

      console.log('   ‚úÖ Pipeline instance created');
      console.log(`   ‚úÖ Data sources enabled: Twitter(${config.data_sources.twitter.enabled}), Telegram(${config.data_sources.telegram.enabled}), RSS(${config.data_sources.rss.enabled})`);
      
      // Test pipeline properties
      const taskName = pipeline.getName();
      const estimatedDuration = pipeline.getEstimatedDuration();
      
      console.log(`   ‚úÖ Pipeline task name: ${taskName}`);
      console.log(`   ‚úÖ Estimated duration: ${(estimatedDuration / 1000 / 60).toFixed(1)} minutes`);

      this.testResults.set('pipeline_components', true);

    } catch (error: any) {
      console.log(`   ‚ùå Pipeline components test failed: ${error.message}`);
      this.testResults.set('pipeline_components', false);
    }
  }

  /**
   * Test scheduler functionality
   */
  private async testScheduler(): Promise<void> {
    try {
      console.log('\n4. Testing Scheduler:');

      // Create a simple test task
      class TestTask {
        async execute(): Promise<void> {
          await new Promise(resolve => setTimeout(resolve, 100));
        }
        getName(): string { return 'test-task'; }
        getEstimatedDuration(): number { return 1000; }
      }

      const testTask = new TestTask();
      
      // Test task scheduling
      const scheduleConfig: ScheduleConfig = {
        name: 'test-automation',
        cronPattern: '*/10 * * * * *', // Every 10 seconds
        enabled: true,
        maxConcurrentRuns: 1,
        retryAttempts: 1,
        retryDelayMs: 1000
      };

      taskScheduler.scheduleTask(scheduleConfig, testTask);
      console.log('   ‚úÖ Task scheduled successfully');

      // Wait for a potential execution
      await new Promise(resolve => setTimeout(resolve, 2000));

      // Check running tasks
      const runningTasks = taskScheduler.getRunningTasks();
      console.log(`   ‚úÖ Running tasks: ${runningTasks.length}`);

      // Check task history
      const taskHistory = taskScheduler.getTaskHistory(5);
      console.log(`   ‚úÖ Task history entries: ${taskHistory.length}`);

      // Get task statistics
      const taskStats = taskScheduler.getTaskStats('test-automation');
      console.log(`   ‚úÖ Task stats: ${taskStats.total_executions} executions, ${(taskStats.success_rate * 100).toFixed(1)}% success rate`);

      // Clean up
      taskScheduler.unscheduleTask('test-automation');
      console.log('   ‚úÖ Task unscheduled');

      this.testResults.set('scheduler', true);

    } catch (error: any) {
      console.log(`   ‚ùå Scheduler test failed: ${error.message}`);
      this.testResults.set('scheduler', false);
    }
  }

  /**
   * Test error handling and recovery
   */
  private async testErrorHandling(): Promise<void> {
    try {
      console.log('\n5. Testing Error Handling:');

      // Create a task that will fail
      class FailingTask {
        private attemptCount = 0;
        
        async execute(): Promise<void> {
          this.attemptCount++;
          if (this.attemptCount < 3) {
            throw new Error(`Simulated failure (attempt ${this.attemptCount})`);
          }
          // Succeed on 3rd attempt
        }
        
        getName(): string { return 'failing-task'; }
        getEstimatedDuration(): number { return 1000; }
      }

      const failingTask = new FailingTask();
      
      const scheduleConfig: ScheduleConfig = {
        name: 'error-test',
        cronPattern: '*/5 * * * * *', // Every 5 seconds
        enabled: true,
        maxConcurrentRuns: 1,
        retryAttempts: 3,
        retryDelayMs: 500
      };

      taskScheduler.scheduleTask(scheduleConfig, failingTask);
      console.log('   ‚úÖ Failing task scheduled');

      // Wait for retries to complete
      await new Promise(resolve => setTimeout(resolve, 8000));

      const taskStats = taskScheduler.getTaskStats('error-test');
      console.log(`   ‚úÖ Error handling test: ${taskStats.total_executions} executions`);
      
      if (taskStats.completed > 0) {
        console.log('   ‚úÖ Task eventually succeeded after retries');
      } else {
        console.log('   ‚ö†Ô∏è  Task failed even with retries');
      }

      // Clean up
      taskScheduler.unscheduleTask('error-test');

      this.testResults.set('error_handling', true);

    } catch (error: any) {
      console.log(`   ‚ùå Error handling test failed: ${error.message}`);
      this.testResults.set('error_handling', false);
    }
  }

  /**
   * Test performance benchmarks
   */
  private async testPerformance(): Promise<void> {
    try {
      console.log('\n6. Testing Performance:');

      const performanceTests = [
        { name: 'Configuration Loading', iterations: 100 },
        { name: 'Health Metric Updates', iterations: 1000 },
        { name: 'Task Scheduling', iterations: 50 }
      ];

      for (const test of performanceTests) {
        const startTime = Date.now();
        
        for (let i = 0; i < test.iterations; i++) {
          switch (test.name) {
            case 'Configuration Loading':
              configManager.getConfig();
              break;
            case 'Health Metric Updates':
              healthMonitor.updateMetric(`perf_test_${i}`, Math.random() * 100, 50);
              break;
            case 'Task Scheduling':
              // Just test the scheduling logic, not actual execution
              break;
          }
        }
        
        const duration = Date.now() - startTime;
        const avgTime = duration / test.iterations;
        
        console.log(`   ‚úÖ ${test.name}: ${duration}ms total, ${avgTime.toFixed(2)}ms avg`);
      }

      // Memory usage check
      const memUsage = process.memoryUsage();
      const memUsedMB = Math.round(memUsage.heapUsed / 1024 / 1024);
      console.log(`   ‚úÖ Memory usage: ${memUsedMB}MB heap used`);

      this.testResults.set('performance', true);

    } catch (error: any) {
      console.log(`   ‚ùå Performance test failed: ${error.message}`);
      this.testResults.set('performance', false);
    }
  }

  /**
   * Test end-to-end pipeline (limited scope for testing)
   */
  private async testEndToEndPipeline(): Promise<void> {
    try {
      console.log('\n7. Testing End-to-End Pipeline:');

      const config = configManager.getConfig();

      // Create a minimal pipeline for testing
      const testPipeline = new DigestPipeline({
        enableTwitter: false, // Disable to avoid API costs
        enableTelegram: true,  // Use free scraping
        enableRSS: true,       // Use free RSS
        aiModel: 'anthropic',
        aiModelName: 'claude-3-haiku-20240307', // Cheapest model
        analysisType: 'summary',
        postToSlack: false,    // Don't post during testing
        minQualityThreshold: 0.3, // Very lenient
        maxContentAge: 168     // 1 week
      });

      console.log('   ‚úÖ Test pipeline created');

      // Record execution for health monitoring
      const startTime = Date.now();
      
      try {
        // Note: We're not actually executing to avoid costs
        // In a real test, you might execute with mock data
        console.log('   ‚úÖ Pipeline execution simulation successful');
        
        const duration = Date.now() - startTime;
        healthMonitor.recordPipelineExecution(true, duration, 100); // Mock token usage
        
        console.log(`   ‚úÖ Execution recorded in health monitoring`);
        
      } catch (pipelineError: any) {
        console.log(`   ‚ö†Ô∏è  Pipeline execution failed: ${pipelineError.message}`);
        healthMonitor.recordPipelineExecution(false, Date.now() - startTime);
      }

      this.testResults.set('end_to_end', true);

    } catch (error: any) {
      console.log(`   ‚ùå End-to-end test failed: ${error.message}`);
      this.testResults.set('end_to_end', false);
    }
  }

  /**
   * Test production readiness
   */
  private async testProductionReadiness(): Promise<void> {
    try {
      console.log('\n8. Testing Production Readiness:');

      const config = configManager.getConfig();
      
      // Check environment variables
      const envValidation = configManager.validateEnvironment();
      if (envValidation.valid) {
        console.log('   ‚úÖ All required environment variables present');
      } else {
        console.log(`   ‚ö†Ô∏è  Missing: ${envValidation.missing.join(', ')}`);
      }

      // Check configuration completeness
      const requiredConfigs = [
        'scheduling.digest_pipeline.cron_pattern',
        'ai.default_provider',
        'quality.min_quality_threshold'
      ];

      let configComplete = true;
      for (const configPath of requiredConfigs) {
        const value = this.getNestedValue(config, configPath);
        if (!value) {
          console.log(`   ‚ùå Missing config: ${configPath}`);
          configComplete = false;
        }
      }

      if (configComplete) {
        console.log('   ‚úÖ Configuration is complete');
      }

      // Check data source availability
      const dataSources = [];
      if (config.data_sources.twitter.enabled) dataSources.push('Twitter');
      if (config.data_sources.telegram.enabled) dataSources.push('Telegram');
      if (config.data_sources.rss.enabled) dataSources.push('RSS');
      
      console.log(`   ‚úÖ Data sources enabled: ${dataSources.join(', ')}`);

      // Check AI configuration
      console.log(`   ‚úÖ AI provider: ${config.ai.default_provider}`);
      console.log(`   ‚úÖ Daily budget: $${config.ai.cost_limits.daily_budget}`);

      // Check monitoring setup
      if (config.monitoring.health_checks) {
        console.log('   ‚úÖ Health monitoring enabled');
      }

      // Overall readiness assessment
      const readinessScore = this.calculateReadinessScore(config, envValidation);
      console.log(`   üìä Production readiness: ${readinessScore}%`);

      if (readinessScore >= 80) {
        console.log('   üöÄ System is production ready!');
      } else {
        console.log('   ‚ö†Ô∏è  System needs additional configuration for production');
      }

      this.testResults.set('production_readiness', true);

    } catch (error: any) {
      console.log(`   ‚ùå Production readiness test failed: ${error.message}`);
      this.testResults.set('production_readiness', false);
    }
  }

  /**
   * Calculate production readiness score
   */
  private calculateReadinessScore(config: any, envValidation: any): number {
    let score = 0;
    const maxScore = 100;

    // Environment variables (25 points)
    if (envValidation.valid) score += 25;

    // Data sources (20 points)
    const enabledSources = [
      config.data_sources.twitter.enabled,
      config.data_sources.telegram.enabled,
      config.data_sources.rss.enabled
    ].filter(Boolean).length;
    score += (enabledSources / 3) * 20;

    // AI configuration (20 points)
    if (config.ai.default_provider) score += 10;
    if (config.ai.cost_limits.daily_budget > 0) score += 10;

    // Monitoring (15 points)
    if (config.monitoring.health_checks) score += 15;

    // Scheduling (10 points)
    if (config.scheduling.digest_pipeline.enabled) score += 10;

    // Distribution (10 points)
    if (config.distribution.slack.enabled) score += 10;

    return Math.round(score);
  }

  /**
   * Get nested configuration value
   */
  private getNestedValue(obj: any, path: string): any {
    return path.split('.').reduce((current, key) => current?.[key], obj);
  }

  /**
   * Print test summary
   */
  private printTestSummary(): void {
    console.log('\nüìä Test Summary:');
    console.log('================================');

    const totalTests = this.testResults.size;
    const passedTests = Array.from(this.testResults.values()).filter(Boolean).length;
    const failedTests = totalTests - passedTests;

    for (const [testName, passed] of this.testResults) {
      const status = passed ? '‚úÖ PASS' : '‚ùå FAIL';
      console.log(`${status} ${testName.replace(/_/g, ' ').toUpperCase()}`);
    }

    console.log('================================');
    console.log(`Total: ${totalTests} | Passed: ${passedTests} | Failed: ${failedTests}`);
    console.log(`Success Rate: ${((passedTests / totalTests) * 100).toFixed(1)}%`);
    
    const totalTime = Date.now() - this.testStartTime;
    console.log(`Total Time: ${(totalTime / 1000).toFixed(2)}s`);

    if (failedTests === 0) {
      console.log('\nüéâ All automation tests passed! System is ready for production.');
    } else {
      console.log(`\n‚ö†Ô∏è  ${failedTests} test(s) failed. Please review the issues above.`);
    }
  }
}

// Run the complete test suite
async function runAutomationTests() {
  const testSuite = new AutomationTestSuite();
  await testSuite.runCompleteTest();
}

// Execute if run directly
if (require.main === module) {
  runAutomationTests()
    .then(() => {
      console.log('\n‚úÖ Test suite completed successfully');
      process.exit(0);
    })
    .catch(error => {
      console.error('Test suite failed:', error);
      process.exit(1);
    });
}

export { runAutomationTests };
```

**Package.json scripts to add:**
```json
{
  "scripts": {
    "test:automation": "npm run script scripts/test/test-automation-complete.ts"
  }
}
```

**Test your automation system:**
```bash
npm run test:automation
```

If you see `Test suite completed successfully` with `Total: 8 | Passed: 8 | Failed: 0` then awesome, all systems are ready!

**What the Test Covers (8 Test Areas):**
- **Configuration Management** - Loading, validating, and updating system config
- **Health Monitoring** - Metric tracking, pipeline execution recording, alert system
- **Pipeline Components** - Creating and configuring digest pipelines
- **Scheduler** - Task scheduling, execution tracking, statistics
- **Error Handling** - Retry mechanisms and failure recovery
- **Performance** - Benchmarking key operations (config loading, metrics, scheduling)
- **End-to-End Pipeline** - Simulated pipeline execution (without actual API calls to avoid costs)
- **Production Readiness** - Environment validation, configuration completeness, readiness scoring

## üöÄ Production Deployment Setup

Now let's create production deployment scripts:

```typescript
// scripts/deploy/setup-production.ts

import { config } from 'dotenv';
import { execSync } from 'child_process';
import { writeFileSync, existsSync, mkdirSync } from 'fs';
import { join } from 'path';

interface DeploymentConfig {
  environment: 'staging' | 'production';
  nodeEnv: string;
  port: number;
  logLevel: string;
  enableHealthCheck: boolean;
  enableMetrics: boolean;
  cronJobs: {
    digestPipeline: string;
    cacheCleanup: string;
    healthCheck: string;
  };
}

class ProductionSetup {
  private deployConfig: DeploymentConfig;

  constructor(environment: 'staging' | 'production' = 'production') {
    this.deployConfig = {
      environment,
      nodeEnv: environment,
      port: environment === 'production' ? 3000 : 3001,
      logLevel: environment === 'production' ? 'info' : 'debug',
      enableHealthCheck: true,
      enableMetrics: true,
      cronJobs: {
        digestPipeline: environment === 'production' ? '0 9 * * *' : '0 */2 * * *', // 9 AM daily vs every 2 hours
        cacheCleanup: '0 2 * * *', // 2 AM daily
        healthCheck: '*/5 * * * *' // Every 5 minutes
      }
    };
  }

  async setupProduction(): Promise<void> {
    console.log(`üöÄ Setting up ${this.deployConfig.environment} environment...\n`);

    try {
      // Step 1: Environment validation
      console.log('1. Validating environment...');
      this.validateEnvironment();
      console.log('   ‚úÖ Environment validation passed');

      // Step 2: Create necessary directories
      console.log('\n2. Creating directory structure...');
      this.createDirectories();
      console.log('   ‚úÖ Directories created');

      // Step 3: Generate production configuration
      console.log('\n3. Generating production configuration...');
      this.generateProductionConfig();
      console.log('   ‚úÖ Configuration generated');

      // Step 4: Setup logging
      console.log('\n4. Setting up logging...');
      this.setupLogging();
      console.log('   ‚úÖ Logging configured');

      // Step 5: Create systemd service (Linux only)
      if (process.platform === 'linux') {
        console.log('\n5. Creating systemd service...');
        this.createSystemdService();
        console.log('   ‚úÖ Systemd service created');
      }

      // Step 6: Setup monitoring
      console.log('\n6. Setting up monitoring...');
      this.setupMonitoring();
      console.log('   ‚úÖ Monitoring configured');

      // Step 7: Create startup script
      console.log('\n7. Creating startup script...');
      this.createStartupScript();
      console.log('   ‚úÖ Startup script created');

      // Step 8: Setup cron jobs
      console.log('\n8. Setting up cron jobs...');
      this.setupCronJobs();
      console.log('   ‚úÖ Cron jobs configured');

      console.log('\nüéâ Production setup completed successfully!');
      this.printNextSteps();

    } catch (error: any) {
      console.error('\n‚ùå Production setup failed:', error.message);
      throw error;
    }
  }

  private validateEnvironment(): void {
    const requiredEnvVars = [
      'NODE_ENV',
      'OPENAI_API_KEY',
      'ANTHROPIC_API_KEY',
      'NEXT_PUBLIC_SUPABASE_URL',
      'SUPABASE_SERVICE_ROLE_KEY'
    ];

    const missing = requiredEnvVars.filter(envVar => !process.env[envVar]);
    
    if (missing.length > 0) {
      throw new Error(`Missing required environment variables: ${missing.join(', ')}`);
    }

    // Check optional but recommended
    const recommended = ['SLACK_BOT_TOKEN', 'SLACK_CHANNEL_ID'];
    const missingRecommended = recommended.filter(envVar => !process.env[envVar]);
    
    if (missingRecommended.length > 0) {
      console.log(`   ‚ö†Ô∏è  Recommended environment variables missing: ${missingRecommended.join(', ')}`);
    }
  }

  private createDirectories(): void {
    const dirs = [
      'logs',
      'config',
      'data',
      'scripts/deploy',
      'monitoring'
    ];

    dirs.forEach(dir => {
      const fullPath = join(process.cwd(), dir);
      if (!existsSync(fullPath)) {
        mkdirSync(fullPath, { recursive: true });
      }
    });
  }

  private generateProductionConfig(): void {
    const productionConfig = {
      environment: this.deployConfig.environment,
      scheduling: {
        digest_pipeline: {
          enabled: true,
          cron_pattern: this.deployConfig.cronJobs.digestPipeline,
          timezone: 'UTC',
          max_concurrent_runs: 1,
          retry_attempts: 3,
          retry_delay_ms: 300000 // 5 minutes
        },
        cache_cleanup: {
          enabled: true,
          cron_pattern: this.deployConfig.cronJobs.cacheCleanup,
          retention_days: 7
        },
        health_check: {
          enabled: this.deployConfig.enableHealthCheck,
          interval_minutes: 5
        }
      },
      data_sources: {
        twitter: {
          enabled: !!process.env.X_API_KEY,
          accounts: ['openai', 'anthropicai', 'elonmusk'],
          api_rate_limit_buffer: 10000
        },
        telegram: {
          enabled: true,
          channels: ['telegram', 'durov'],
          scraping_delay_ms: 5000
        },
        rss: {
          enabled: true,
          feeds: [
            'https://techcrunch.com/feed/',
            'https://www.theverge.com/rss/index.xml',
            'https://feeds.feedburner.com/venturebeat/SZYF'
          ],
          timeout_ms: 30000
        }
      },
      ai: {
        default_provider: 'anthropic',
        model_configs: {
          routine: {
            provider: 'openai',
            model: 'gpt-4o-mini',
            max_tokens: 1500,
            temperature: 0.7
          },
          important: {
            provider: 'anthropic',
            model: 'claude-3-5-sonnet-20241022',
            max_tokens: 2500,
            temperature: 0.7
          },
          critical: {
            provider: 'anthropic',
            model: 'claude-3-5-sonnet-20241022',
            max_tokens: 4000,
            temperature: 0.3
          }
        },
        cost_limits: {
          daily_budget: this.deployConfig.environment === 'production' ? 25.0 : 5.0,
          per_analysis_limit: this.deployConfig.environment === 'production' ? 5.0 : 1.0
        }
      },
      quality: {
        min_quality_threshold: 0.7,
        max_content_age_hours: 24,
        min_engagement_threshold: 10
      },
      distribution: {
        slack: {
          enabled: !!process.env.SLACK_BOT_TOKEN,
          channel_id: process.env.SLACK_CHANNEL_ID || ''
        },
        webhook_notifications: {
          enabled: false,
          endpoints: []
        }
      },
      monitoring: {
        health_checks: this.deployConfig.enableHealthCheck,
        alert_webhooks: [],
        log_level: this.deployConfig.logLevel,
        metrics_retention_days: 30
      }
    };

    const configPath = join(process.cwd(), 'config', 'automation.json');
    writeFileSync(configPath, JSON.stringify(productionConfig, null, 2));
  }

  private setupLogging(): void {
    const logConfig = {
      level: this.deployConfig.logLevel,
      format: 'json',
      transports: [
        {
          type: 'file',
          filename: 'logs/application.log',
          maxsize: 10485760, // 10MB
          maxFiles: 5
        },
        {
          type: 'file',
          filename: 'logs/error.log',
          level: 'error',
          maxsize: 10485760,
          maxFiles: 5
        }
      ]
    };

    if (this.deployConfig.environment !== 'production') {
      logConfig.transports.push({
        type: 'console',
        format: 'simple'
      } as any);
    }

    const configPath = join(process.cwd(), 'config', 'logging.json');
    writeFileSync(configPath, JSON.stringify(logConfig, null, 2));
  }

  private createSystemdService(): void {
    const serviceName = `cl-digest-bot-${this.deployConfig.environment}`;
    const serviceFile = `[Unit]
Description=CL Digest Bot ${this.deployConfig.environment}
After=network.target

[Service]
Type=simple
User=nodejs
WorkingDirectory=${process.cwd()}
Environment=NODE_ENV=${this.deployConfig.nodeEnv}
Environment=PORT=${this.deployConfig.port}
ExecStart=/usr/bin/node scripts/deploy/start-production.js
Restart=always
RestartSec=10
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=${serviceName}

[Install]
WantedBy=multi-user.target`;

    const servicePath = join(process.cwd(), 'scripts', 'deploy', `${serviceName}.service`);
    writeFileSync(servicePath, serviceFile);

    console.log(`   üìÑ Systemd service file created: ${serviceName}.service`);
    console.log(`   üí° Copy to /etc/systemd/system/ and run:`);
    console.log(`      sudo systemctl daemon-reload`);
    console.log(`      sudo systemctl enable ${serviceName}`);
    console.log(`      sudo systemctl start ${serviceName}`);
  }

  private setupMonitoring(): void {
    // Create a simple health check endpoint
    const healthCheckScript = `#!/usr/bin/env node
const http = require('http');

const options = {
  hostname: 'localhost',
  port: ${this.deployConfig.port},
  path: '/health',
  method: 'GET',
  timeout: 5000
};

const req = http.request(options, (res) => {
  if (res.statusCode === 200) {
    console.log('Health check passed');
    process.exit(0);
  } else {
    console.log(\`Health check failed: \${res.statusCode}\`);
    process.exit(1);
  }
});

req.on('error', (err) => {
  console.log(\`Health check error: \${err.message}\`);
  process.exit(1);
});

req.on('timeout', () => {
  console.log('Health check timeout');
  req.destroy();
  process.exit(1);
});

req.end();`;

    const healthCheckPath = join(process.cwd(), 'scripts', 'deploy', 'health-check.js');
    writeFileSync(healthCheckPath, healthCheckScript);
    
    // Make it executable
    try {
      execSync(`chmod +x ${healthCheckPath}`);
    } catch (error) {
      // Ignore on Windows
    }
  }

  private createStartupScript(): void {
    const startupScript = `#!/usr/bin/env node

// Production startup script
const { spawn } = require('child_process');
const path = require('path');

console.log('üöÄ Starting CL Digest Bot in production mode...');

// Set production environment
process.env.NODE_ENV = '${this.deployConfig.nodeEnv}';
process.env.PORT = '${this.deployConfig.port}';

// Start the application
const appProcess = spawn('node', ['scripts/automation/start-automation.js'], {
  stdio: 'inherit',
  cwd: process.cwd()
});

appProcess.on('error', (error) => {
  console.error('Failed to start application:', error);
  process.exit(1);
});

appProcess.on('exit', (code) => {
  console.log(\`Application exited with code \${code}\`);
  process.exit(code);
});

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('Received SIGTERM, shutting down gracefully...');
  appProcess.kill('SIGTERM');
});

process.on('SIGINT', () => {
  console.log('Received SIGINT, shutting down gracefully...');
  appProcess.kill('SIGINT');
});`;

    const startupPath = join(process.cwd(), 'scripts', 'deploy', 'start-production.js');
    writeFileSync(startupPath, startupScript);
    
    try {
      execSync(`chmod +x ${startupPath}`);
    } catch (error) {
      // Ignore on Windows
    }
  }

  private setupCronJobs(): void {
    const cronEntries = [
      `# CL Digest Bot - ${this.deployConfig.environment}`,
      `${this.deployConfig.cronJobs.digestPipeline} cd ${process.cwd()} && node scripts/automation/run-digest.js >> logs/cron.log 2>&1`,
      `${this.deployConfig.cronJobs.cacheCleanup} cd ${process.cwd()} && node scripts/automation/cleanup-cache.js >> logs/cron.log 2>&1`,
      `${this.deployConfig.cronJobs.healthCheck} cd ${process.cwd()} && node scripts/deploy/health-check.js >> logs/health.log 2>&1`,
      '' // Empty line at end
    ];

    const crontabPath = join(process.cwd(), 'scripts', 'deploy', 'crontab');
    writeFileSync(crontabPath, cronEntries.join('\n'));

    console.log('   üìÑ Crontab file created');
    console.log('   üí° Install with: crontab scripts/deploy/crontab');
  }

  private printNextSteps(): void {
    console.log('\nüìã Next Steps:');
    console.log('==============');
    console.log('1. Review configuration files in config/');
    console.log('2. Test the setup: npm run test:automation-complete');
    console.log('3. Start the application: node scripts/deploy/start-production.js');
    
    if (process.platform === 'linux') {
      console.log('4. Install systemd service (optional):');
      console.log('   sudo cp scripts/deploy/*.service /etc/systemd/system/');
      console.log('   sudo systemctl daemon-reload');
      console.log('   sudo systemctl enable cl-digest-bot-production');
      console.log('   sudo systemctl start cl-digest-bot-production');
    }
    
    console.log('5. Install cron jobs: crontab scripts/deploy/crontab');
    console.log('6. Monitor logs: tail -f logs/application.log');
    console.log('7. Check health: node scripts/deploy/health-check.js');
    
    console.log('\nüîß Useful Commands:');
    console.log('==================');
    console.log('‚Ä¢ Check status: npm run test:automation-complete');
    console.log('‚Ä¢ View logs: tail -f logs/application.log');
    console.log('‚Ä¢ Health check: node scripts/deploy/health-check.js');
    console.log('‚Ä¢ Stop safely: pkill -SIGTERM -f "start-production"');
  }
}

// CLI interface
async function main() {
  const args = process.argv.slice(2);
  const environment = args[0] === 'staging' ? 'staging' : 'production';
  
  const setup = new ProductionSetup(environment);
  await setup.setupProduction();
}

if (require.main === module) {
  main().catch(error => {
    console.error('Setup failed:', error);
    process.exit(1);
  });
}
```

## üöÄ About the Production Setup Script

The `/scripts/deploy/setup-production.js` script we just created is your **one-click production deployment tool**. Here's what it does:

### What the Script Sets Up:
- **üîß Production Configuration** - Creates optimized config files for production environment
- **üì¶ Systemd Services** - Linux service files for automatic startup and crash recovery  
- **‚è∞ Cron Jobs** - Automated scheduling for digest pipeline, cache cleanup, and health checks
- **üìä Health Monitoring** - Endpoint monitoring and status checking scripts
- **üîÑ Startup Scripts** - Production-ready application startup with graceful shutdown
- **üìù Log Configuration** - Structured logging with proper rotation

### When to Run It:
**üü° NOT YET!** Don't run this script now. Here's the roadmap:

### üìÖ Tutorial Roadmap - What's Left:

**Chapter 10: Social Media Distribution** *(Next)*
- Multi-platform posting (Twitter, Instagram, TikTok, YouTube)
- Automated video generation with FFmpeg
- Social media analytics and performance tracking
- Content adaptation for different platforms

**Chapter 11: Team Collaboration** *(After Chapter 10)*
- Advanced Slack integration with interactive workflows
- User management and role-based permissions
- Collaborative content review and approval processes
- Team analytics and reporting dashboards

**Chapter 12: Production Deployment** *(Final Chapter)*
- **‚ö° This is when you'll run the setup script!**
- Docker containerization and Kubernetes deployment
- CI/CD pipelines with GitHub Actions
- Production monitoring with Prometheus and Grafana
- Security hardening and backup strategies

### üéØ The Complete Flow:
1. **Chapters 1-9** ‚úÖ - Build the complete system locally
2. **Chapter 10** üîÑ - Add social media distribution
3. **Chapter 11** üîÑ - Enable team collaboration  
4. **Chapter 12** üîÑ - Deploy to production (run setup script here!)

**Why wait?** The production setup script creates systemd services and cron jobs that expect the full system to be complete, including social media distribution and team collaboration features we haven't built yet.

**Next up:** Chapter 10 will add the social media distribution layer, turning your digest bot into a content powerhouse that automatically posts across platforms! üöÄ